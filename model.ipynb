{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/01/25 14:10:29 WARN Utils: Your hostname, Device02072004 resolves to a loopback address: 127.0.1.1; using 172.24.50.213 instead (on interface eth0)\n",
      "25/01/25 14:10:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/25 14:10:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/01/25 14:10:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/01/25 14:10:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .config(\"spark.task.maxDirectResultSize\", \"4m\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/25 14:11:15 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df_train = spark.read.csv(\"Cleaned_dataset.csv\", header=True, inferSchema=True)\n",
    "print(df_train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+---------+-----------+-------+------+------------+-----------+------------+-----------+-----------------+---------+----+\n",
      "|Date_of_journey|Journey_day|  Airline|Flight_code|  Class|Source|   Departure|Total_stops|     Arrival|Destination|Duration_in_hours|Days_left|Fare|\n",
      "+---------------+-----------+---------+-----------+-------+------+------------+-----------+------------+-----------+-----------------+---------+----+\n",
      "|     2023-01-16|     Monday| SpiceJet|    SG-8169|Economy| Delhi|  After 6 PM|   non-stop|  After 6 PM|     Mumbai|           2.0833|        1|5335|\n",
      "|     2023-01-16|     Monday|   Indigo|    6E-2519|Economy| Delhi|  After 6 PM|   non-stop| Before 6 AM|     Mumbai|           2.3333|        1|5899|\n",
      "|     2023-01-16|     Monday| GO FIRST|     G8-354|Economy| Delhi|  After 6 PM|   non-stop| Before 6 AM|     Mumbai|           2.1667|        1|5801|\n",
      "|     2023-01-16|     Monday| SpiceJet|    SG-8709|Economy| Delhi|  After 6 PM|   non-stop|  After 6 PM|     Mumbai|           2.0833|        1|5794|\n",
      "|     2023-01-16|     Monday|Air India|     AI-805|Economy| Delhi|  After 6 PM|   non-stop|  After 6 PM|     Mumbai|           2.1667|        1|5955|\n",
      "|     2023-01-16|     Monday|Air India|     AI-605|Economy| Delhi|  After 6 PM|   non-stop|  After 6 PM|     Mumbai|             2.25|        1|5955|\n",
      "|     2023-01-16|     Monday|Air India|     AI-814|Economy| Delhi|  After 6 PM|   non-stop| Before 6 AM|     Mumbai|             2.25|        1|5955|\n",
      "|     2023-01-16|     Monday| GO FIRST|     G8-330|Economy| Delhi|  After 6 PM|   non-stop|  After 6 PM|     Mumbai|             2.25|        1|5899|\n",
      "|     2023-01-16|     Monday| SpiceJet|    SG-2976|Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          14.3333|        1|5829|\n",
      "|     2023-01-16|     Monday| GO FIRST|     G8-346|Economy| Delhi|  After 6 PM|   non-stop|  After 6 PM|     Mumbai|           2.0833|        1|5899|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-743|Economy| Delhi| Before 6 AM|     1-stop|  After 6 PM|     Mumbai|          14.6667|        1|6640|\n",
      "|     2023-01-16|     Monday|   Indigo|    6E-2208|Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|           8.6667|        1|6390|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-857|Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|           5.5833|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-773|Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|           6.3333|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-773|Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|              8.0|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-784|Economy| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|           8.1667|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|    I5-1228|Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|              9.5|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-740|Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|          10.8333|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|     I5-773|Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          10.9167|        1|6872|\n",
      "|     2023-01-16|     Monday|  AirAsia|    I5-1228|Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|             11.5|        1|6872|\n",
      "+---------------+-----------+---------+-----------+-------+------+------------+-----------+------------+-----------+-----------------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[38;5;241m.\u001b[39mdropDuplicates()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_train\u001b[38;5;241m.\u001b[39mcount())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train = df_train.dropDuplicates()\n",
    "print(df_train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/25 13:03:45 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 14:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---------+--------------------+---------------+---------+------------+-----------+------------+-----------+-----------------+------------------+------------------+\n",
      "|summary|Journey_day|  Airline|         Flight_code|          Class|   Source|   Departure|Total_stops|     Arrival|Destination|Duration_in_hours|         Days_left|              Fare|\n",
      "+-------+-----------+---------+--------------------+---------------+---------+------------+-----------+------------+-----------+-----------------+------------------+------------------+\n",
      "|  count|     445366|   445366|              445366|         445366|   445366|      445366|     445366|      445366|     445366|           445366|            445366|            445366|\n",
      "|   mean|       NULL|     NULL|6.478977189753123...|           NULL|     NULL|        NULL|       NULL|        NULL|       NULL|12.18249122407184|25.617822195677263|22919.747165252847|\n",
      "| stddev|       NULL|     NULL|4.84548855775472E...|           NULL|     NULL|        NULL|       NULL|        NULL|       NULL|7.299361062179697|14.302610494392454|20394.214039669998|\n",
      "|    min|     Friday|Air India|              6E-107|       Business|Ahmedabad|12 PM - 6 PM|     1-stop|12 PM - 6 PM|  Ahmedabad|             0.75|                 1|              1307|\n",
      "|    max|  Wednesday|  Vistara|              UK-997|Premium Economy|   Mumbai| Before 6 AM|   non-stop| Before 6 AM|     Mumbai|          43.5833|                50|            143019|\n",
      "+-------+-----------+---------+--------------------+---------------+---------+------------+-----------+------------+-----------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------+-------+-----------+-----+------+---------+-----------+-------+-----------+-----------------+---------+----+\n",
      "|Date_of_journey|Journey_day|Airline|Flight_code|Class|Source|Departure|Total_stops|Arrival|Destination|Duration_in_hours|Days_left|Fare|\n",
      "+---------------+-----------+-------+-----------+-----+------+---------+-----------+-------+-----------+-----------------+---------+----+\n",
      "|              0|          0|      0|          0|    0|     0|        0|          0|      0|          0|                0|        0|   0|\n",
      "+---------------+-----------+-------+-----------+-----+------+---------+-----------+-------+-----------+-----------------+---------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Đếm số lượng giá trị null trong mỗi cột\n",
    "null_counts = df_train.select(\n",
    "    [sum(col(c).isNull().cast(\"int\")).alias(c) for c in df_train.columns]\n",
    ")\n",
    "\n",
    "# Hiển thị kết quả\n",
    "null_counts.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| Fare|count|\n",
      "+-----+-----+\n",
      "|54879| 2702|\n",
      "|54608| 2521|\n",
      "|49613| 2128|\n",
      "|49713| 2089|\n",
      "|41549| 1842|\n",
      "|42457| 1772|\n",
      "|14447| 1743|\n",
      "|50289| 1708|\n",
      "|42716| 1604|\n",
      "|49725| 1536|\n",
      "| 8895| 1360|\n",
      "|60703| 1323|\n",
      "|45345| 1271|\n",
      "| 5955| 1240|\n",
      "|16494| 1159|\n",
      "|45257| 1158|\n",
      "|12262| 1140|\n",
      "|60996| 1134|\n",
      "|46118| 1086|\n",
      "| 9840| 1069|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Đếm số lần xuất hiện của từng giá trị trong cột Total_stops\n",
    "df_train.groupBy(\"Fare\").count().orderBy(col(\"count\").desc()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:=======>                                                  (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+\n",
      "|Journey_day|  Airline|Flight_code|          Class|Source|   Departure|Total_stops|     Arrival|Destination|Duration_in_hours|Days_left| Fare|Journey_month|\n",
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+\n",
      "|     Monday|   Indigo|    6E-2328|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|        1| 8894|            1|\n",
      "|     Monday|Air India|     AI-544|        Economy| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        1|11205|            1|\n",
      "|     Monday|  Vistara|     UK-809|       Business| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.4167|        1|73414|            1|\n",
      "|  Wednesday|Air India|     AI-883|        Economy| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          18.8333|        3|11344|            1|\n",
      "|     Friday| GO FIRST|    G8-2501|        Economy| Delhi| Before 6 AM|   non-stop| Before 6 AM|     Mumbai|           2.1667|        5| 5801|            1|\n",
      "|     Friday|   Indigo|    6E-6034|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|           5.0833|        5| 7330|            1|\n",
      "|     Friday|Air India|     AI-817|       Business| Delhi| Before 6 AM|     1-stop|  After 6 PM|     Mumbai|          17.1667|        5|31462|            1|\n",
      "|   Saturday|Air India|     AI-839|       Business| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          17.4167|        6|41113|            1|\n",
      "|     Sunday|  Vistara|     UK-871|Premium Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          11.5833|        7|21200|            1|\n",
      "|     Sunday|  Vistara|     UK-871|       Business| Delhi|  After 6 PM|     1-stop|  After 6 PM|     Mumbai|             26.5|        7|55696|            1|\n",
      "|     Monday|  AirAsia|    I5-1228|        Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|             11.5|        8| 5291|            1|\n",
      "|     Monday|Air India|     AI-544|       Business| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        8|41113|            1|\n",
      "|     Monday|  Vistara|     UK-879|       Business| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          14.6667|        8|41281|            1|\n",
      "|  Wednesday|   Indigo|    6E-2328|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|       10| 6682|            1|\n",
      "|  Wednesday|   Indigo|    6E-6231|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|              4.5|       10| 9788|            1|\n",
      "|  Wednesday|  Vistara|     UK-835|        Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.8333|       10|12203|            1|\n",
      "|  Wednesday|  Vistara|     UK-637|Premium Economy| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|             18.5|       10|11982|            1|\n",
      "|     Friday| GO FIRST|     G8-530|        Economy| Delhi|6 AM - 12 PM|   non-stop|6 AM - 12 PM|     Mumbai|           2.1667|       12| 5899|            1|\n",
      "|     Friday|Air India|     AI-636|        Economy| Delhi|12 PM - 6 PM|     1-stop|  After 6 PM|     Mumbai|             3.75|       12| 7320|            1|\n",
      "|     Friday|  Vistara|     UK-855|        Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|           5.5833|       12|13830|            1|\n",
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, col\n",
    "\n",
    "# Tách cột 'Date_of_journey' và tạo cột mới 'Journey_month'\n",
    "df_train = df_train.withColumn(\"Journey_month\", split(col(\"Date_of_journey\"), \"-\")[1].cast(\"int\"))\n",
    "\n",
    "# Loại bỏ cột 'Date_of_journey'\n",
    "df_train = df_train.drop(\"Date_of_journey\")\n",
    "\n",
    "# Hiển thị kết quả\n",
    "df_train.show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=====================>                                    (3 + 5) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "|Journey_day|  Airline|Flight_code|          Class|Source|   Departure|Total_stops|     Arrival|Destination|Duration_in_hours|Days_left| Fare|Journey_month|Weekend|\n",
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "|     Monday|   Indigo|    6E-2328|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|        1| 8894|            1|      0|\n",
      "|     Monday|Air India|     AI-544|        Economy| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        1|11205|            1|      0|\n",
      "|     Monday|  Vistara|     UK-809|       Business| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.4167|        1|73414|            1|      0|\n",
      "|  Wednesday|Air India|     AI-883|        Economy| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          18.8333|        3|11344|            1|      0|\n",
      "|     Friday| GO FIRST|    G8-2501|        Economy| Delhi| Before 6 AM|   non-stop| Before 6 AM|     Mumbai|           2.1667|        5| 5801|            1|      0|\n",
      "|     Friday|   Indigo|    6E-6034|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|           5.0833|        5| 7330|            1|      0|\n",
      "|     Friday|Air India|     AI-817|       Business| Delhi| Before 6 AM|     1-stop|  After 6 PM|     Mumbai|          17.1667|        5|31462|            1|      0|\n",
      "|   Saturday|Air India|     AI-839|       Business| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          17.4167|        6|41113|            1|      0|\n",
      "|     Sunday|  Vistara|     UK-871|Premium Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          11.5833|        7|21200|            1|      1|\n",
      "|     Sunday|  Vistara|     UK-871|       Business| Delhi|  After 6 PM|     1-stop|  After 6 PM|     Mumbai|             26.5|        7|55696|            1|      1|\n",
      "|     Monday|  AirAsia|    I5-1228|        Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|             11.5|        8| 5291|            1|      0|\n",
      "|     Monday|Air India|     AI-544|       Business| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        8|41113|            1|      0|\n",
      "|     Monday|  Vistara|     UK-879|       Business| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          14.6667|        8|41281|            1|      0|\n",
      "|  Wednesday|   Indigo|    6E-2328|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|       10| 6682|            1|      0|\n",
      "|  Wednesday|   Indigo|    6E-6231|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|              4.5|       10| 9788|            1|      0|\n",
      "|  Wednesday|  Vistara|     UK-835|        Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.8333|       10|12203|            1|      0|\n",
      "|  Wednesday|  Vistara|     UK-637|Premium Economy| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|             18.5|       10|11982|            1|      0|\n",
      "|     Friday| GO FIRST|     G8-530|        Economy| Delhi|6 AM - 12 PM|   non-stop|6 AM - 12 PM|     Mumbai|           2.1667|       12| 5899|            1|      0|\n",
      "|     Friday|Air India|     AI-636|        Economy| Delhi|12 PM - 6 PM|     1-stop|  After 6 PM|     Mumbai|             3.75|       12| 7320|            1|      0|\n",
      "|     Friday|  Vistara|     UK-855|        Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|           5.5833|       12|13830|            1|      0|\n",
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as f\n",
    "\n",
    "# Add a new column 'Weekend' based on the 'Journey_day' column\n",
    "df_train = df_train.withColumn(\"Weekend\", f.when(df_train[\"Journey_day\"] == \"Sunday\", 1).otherwise(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "|Journey_day|  Airline|Flight_code|          Class|Source|   Departure|Total_stops|     Arrival|Destination|Duration_in_hours|Days_left| Fare|Journey_month|Weekend|\n",
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "|     Monday|   Indigo|    6E-2328|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|        1| 8894|            1|      0|\n",
      "|     Monday|Air India|     AI-544|        Economy| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        1|11205|            1|      0|\n",
      "|     Monday|  Vistara|     UK-809|       Business| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.4167|        1|73414|            1|      0|\n",
      "|  Wednesday|Air India|     AI-883|        Economy| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          18.8333|        3|11344|            1|      0|\n",
      "|     Friday| GO FIRST|    G8-2501|        Economy| Delhi| Before 6 AM|   non-stop| Before 6 AM|     Mumbai|           2.1667|        5| 5801|            1|      0|\n",
      "|     Friday|   Indigo|    6E-6034|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|           5.0833|        5| 7330|            1|      0|\n",
      "|     Friday|Air India|     AI-817|       Business| Delhi| Before 6 AM|     1-stop|  After 6 PM|     Mumbai|          17.1667|        5|31462|            1|      0|\n",
      "|   Saturday|Air India|     AI-839|       Business| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          17.4167|        6|41113|            1|      0|\n",
      "|     Sunday|  Vistara|     UK-871|Premium Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          11.5833|        7|21200|            1|      1|\n",
      "|     Sunday|  Vistara|     UK-871|       Business| Delhi|  After 6 PM|     1-stop|  After 6 PM|     Mumbai|             26.5|        7|55696|            1|      1|\n",
      "|     Monday|  AirAsia|    I5-1228|        Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|             11.5|        8| 5291|            1|      0|\n",
      "|     Monday|Air India|     AI-544|       Business| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        8|41113|            1|      0|\n",
      "|     Monday|  Vistara|     UK-879|       Business| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          14.6667|        8|41281|            1|      0|\n",
      "|  Wednesday|   Indigo|    6E-2328|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|       10| 6682|            1|      0|\n",
      "|  Wednesday|   Indigo|    6E-6231|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|              4.5|       10| 9788|            1|      0|\n",
      "|  Wednesday|  Vistara|     UK-835|        Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.8333|       10|12203|            1|      0|\n",
      "|  Wednesday|  Vistara|     UK-637|Premium Economy| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|             18.5|       10|11982|            1|      0|\n",
      "|     Friday| GO FIRST|     G8-530|        Economy| Delhi|6 AM - 12 PM|   non-stop|6 AM - 12 PM|     Mumbai|           2.1667|       12| 5899|            1|      0|\n",
      "|     Friday|Air India|     AI-636|        Economy| Delhi|12 PM - 6 PM|     1-stop|  After 6 PM|     Mumbai|             3.75|       12| 7320|            1|      0|\n",
      "|     Friday|  Vistara|     UK-855|        Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|           5.5833|       12|13830|            1|      0|\n",
      "+-----------+---------+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "|Journey_day|          Class|Source|   Departure|Total_stops|     Arrival|Destination|Duration_in_hours|Days_left| Fare|Journey_month|Weekend|\n",
      "+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "|     Monday|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|        1| 8894|            1|      0|\n",
      "|     Monday|        Economy| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        1|11205|            1|      0|\n",
      "|     Monday|       Business| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.4167|        1|73414|            1|      0|\n",
      "|  Wednesday|        Economy| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          18.8333|        3|11344|            1|      0|\n",
      "|     Friday|        Economy| Delhi| Before 6 AM|   non-stop| Before 6 AM|     Mumbai|           2.1667|        5| 5801|            1|      0|\n",
      "|     Friday|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|           5.0833|        5| 7330|            1|      0|\n",
      "|     Friday|       Business| Delhi| Before 6 AM|     1-stop|  After 6 PM|     Mumbai|          17.1667|        5|31462|            1|      0|\n",
      "|   Saturday|       Business| Delhi|  After 6 PM|     1-stop|12 PM - 6 PM|     Mumbai|          17.4167|        6|41113|            1|      0|\n",
      "|     Sunday|Premium Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          11.5833|        7|21200|            1|      1|\n",
      "|     Sunday|       Business| Delhi|  After 6 PM|     1-stop|  After 6 PM|     Mumbai|             26.5|        7|55696|            1|      1|\n",
      "|     Monday|        Economy| Delhi|6 AM - 12 PM|     1-stop|  After 6 PM|     Mumbai|             11.5|        8| 5291|            1|      0|\n",
      "|     Monday|       Business| Delhi|12 PM - 6 PM|     1-stop| Before 6 AM|     Mumbai|             7.25|        8|41113|            1|      0|\n",
      "|     Monday|       Business| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          14.6667|        8|41281|            1|      0|\n",
      "|  Wednesday|        Economy| Delhi|6 AM - 12 PM|   non-stop|12 PM - 6 PM|     Mumbai|           2.5833|       10| 6682|            1|      0|\n",
      "|  Wednesday|        Economy| Delhi| Before 6 AM|     1-stop|6 AM - 12 PM|     Mumbai|              4.5|       10| 9788|            1|      0|\n",
      "|  Wednesday|        Economy| Delhi|  After 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|          12.8333|       10|12203|            1|      0|\n",
      "|  Wednesday|Premium Economy| Delhi|12 PM - 6 PM|     1-stop|6 AM - 12 PM|     Mumbai|             18.5|       10|11982|            1|      0|\n",
      "|     Friday|        Economy| Delhi|6 AM - 12 PM|   non-stop|6 AM - 12 PM|     Mumbai|           2.1667|       12| 5899|            1|      0|\n",
      "|     Friday|        Economy| Delhi|12 PM - 6 PM|     1-stop|  After 6 PM|     Mumbai|             3.75|       12| 7320|            1|      0|\n",
      "|     Friday|        Economy| Delhi|  After 6 PM|     1-stop| Before 6 AM|     Mumbai|           5.5833|       12|13830|            1|      0|\n",
      "+-----------+---------------+------+------------+-----------+------------+-----------+-----------------+---------+-----+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Drop the 'Airline' and 'Flight_code' columns\n",
    "df_train = df_train.drop(\"Airline\", \"Flight_code\")\n",
    "\n",
    "# Show the result\n",
    "df_train.show(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Journey_day', 'string'),\n",
       " ('Class', 'string'),\n",
       " ('Source', 'string'),\n",
       " ('Departure', 'string'),\n",
       " ('Total_stops', 'string'),\n",
       " ('Arrival', 'string'),\n",
       " ('Destination', 'string'),\n",
       " ('Duration_in_hours', 'double'),\n",
       " ('Days_left', 'int'),\n",
       " ('Fare', 'int'),\n",
       " ('Journey_month', 'int'),\n",
       " ('Weekend', 'int')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns and their data types\n",
    "columns_and_types = df_train.dtypes\n",
    "# Separate categorical and numerical columns\n",
    "categorical_columns = [col for col, dtype in columns_and_types if dtype == 'string']\n",
    "numerical_columns = [col for col, dtype in columns_and_types if dtype in ['int', 'double']]\n",
    "\n",
    "# Select categorical data\n",
    "train_categorical_data_pyspark = df_train.select(*categorical_columns)\n",
    "\n",
    "# Select numerical data\n",
    "train_numerical_data_pyspark = df_train.select(*numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-----+-------------+-------+\n",
      "|Duration_in_hours|Days_left| Fare|Journey_month|Weekend|\n",
      "+-----------------+---------+-----+-------------+-------+\n",
      "|           2.5833|        1| 8894|            1|      0|\n",
      "|             7.25|        1|11205|            1|      0|\n",
      "|          12.4167|        1|73414|            1|      0|\n",
      "|          18.8333|        3|11344|            1|      0|\n",
      "|           2.1667|        5| 5801|            1|      0|\n",
      "|           5.0833|        5| 7330|            1|      0|\n",
      "|          17.1667|        5|31462|            1|      0|\n",
      "|          17.4167|        6|41113|            1|      0|\n",
      "|          11.5833|        7|21200|            1|      1|\n",
      "|             26.5|        7|55696|            1|      1|\n",
      "|             11.5|        8| 5291|            1|      0|\n",
      "|             7.25|        8|41113|            1|      0|\n",
      "|          14.6667|        8|41281|            1|      0|\n",
      "|           2.5833|       10| 6682|            1|      0|\n",
      "|              4.5|       10| 9788|            1|      0|\n",
      "|          12.8333|       10|12203|            1|      0|\n",
      "|             18.5|       10|11982|            1|      0|\n",
      "|           2.1667|       12| 5899|            1|      0|\n",
      "|             3.75|       12| 7320|            1|      0|\n",
      "|           5.5833|       12|13830|            1|      0|\n",
      "+-----------------+---------+-----+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_numerical_data_pyspark.show(20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_categorical_data_pyspark = spark.createDataFrame(train_categorical_data)\n",
    "# train_numerical_data_pyspark = spark.createDataFrame(train_numerical_data)\n",
    "# df_pyspark = spark.createDataFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Duration_in_hours: double (nullable = true)\n",
      " |-- Days_left: integer (nullable = true)\n",
      " |-- Fare: integer (nullable = true)\n",
      " |-- Journey_month: integer (nullable = true)\n",
      " |-- Weekend: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_numerical_data_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Journey_day: string (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Departure: string (nullable = true)\n",
      " |-- Total_stops: string (nullable = true)\n",
      " |-- Arrival: string (nullable = true)\n",
      " |-- Destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_categorical_data_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Journey_day: string (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      " |-- Departure: string (nullable = true)\n",
      " |-- Total_stops: string (nullable = true)\n",
      " |-- Arrival: string (nullable = true)\n",
      " |-- Destination: string (nullable = true)\n",
      " |-- Duration_in_hours: double (nullable = true)\n",
      " |-- Days_left: integer (nullable = true)\n",
      " |-- Fare: integer (nullable = true)\n",
      " |-- Journey_month: integer (nullable = true)\n",
      " |-- Weekend: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_iindex\",handleInvalid=\"keep\") for col in train_categorical_data_pyspark.columns]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_iindex\", outputCol=f\"{col}Vec\",handleInvalid=\"keep\") for col in train_categorical_data_pyspark.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col + \"Vec\" for col in train_categorical_data_pyspark.columns] + [col for col in train_numerical_data_pyspark.columns] \n",
    "feature_columns.remove(\"Fare\")\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Journey_dayVec',\n",
       " 'ClassVec',\n",
       " 'SourceVec',\n",
       " 'DepartureVec',\n",
       " 'Total_stopsVec',\n",
       " 'ArrivalVec',\n",
       " 'DestinationVec',\n",
       " 'Duration_in_hours',\n",
       " 'Days_left',\n",
       " 'Journey_month',\n",
       " 'Weekend']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_columns.pop(9)\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic Regression model\n",
    "from pyspark.ml.regression import LinearRegression \n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Fare\",maxIter=30, regParam=0.3, elasticNetParam=0.8)\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_train.repartition(200)\n",
    "train_set, test_set = df_pyspark.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/25 13:20:40 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/01/25 13:20:40 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 879:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features|  Fare|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|(47,[2,9,19,23,26...| 75780|55111.660733053795|\n",
      "|(47,[2,9,19,23,26...| 52215|54438.682036834085|\n",
      "|(47,[2,9,19,23,26...| 35587|51342.043518405335|\n",
      "|(47,[2,9,19,23,26...| 33828| 45834.35634207111|\n",
      "|(47,[2,9,19,23,26...| 41508| 53545.88953672675|\n",
      "|(47,[2,9,19,23,26...| 41508| 52165.33005680445|\n",
      "|(47,[2,9,19,23,26...| 53204| 47703.16518286342|\n",
      "|(47,[2,9,19,23,26...| 68052| 56423.37585885548|\n",
      "|(47,[2,9,19,21,26...| 68724| 52269.31857352003|\n",
      "|(47,[2,9,19,21,26...| 59652| 54503.09771967231|\n",
      "|(47,[2,9,19,21,26...| 61302| 50162.28251023708|\n",
      "|(47,[2,9,19,21,26...| 47220| 52504.81778319011|\n",
      "|(47,[2,9,19,21,26...| 41780| 50367.41838733596|\n",
      "|(47,[2,9,19,21,26...| 47332|  58207.9039480182|\n",
      "|(47,[2,9,19,21,26...| 41508|51394.943585044995|\n",
      "|(47,[2,9,19,21,26...| 29292|50126.718058910665|\n",
      "|(47,[2,9,19,21,26...| 52215|54159.488167386386|\n",
      "|(47,[2,9,19,21,26...|106203| 53754.37263672592|\n",
      "|(47,[2,9,19,21,26...| 68881| 53253.53985077987|\n",
      "|(47,[2,9,19,21,26...| 41508| 55594.10100139148|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_pred.select(\"features\", \"Fare\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 890:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 8027.679286892896\n",
      "Mean Absolute Error (MAE): 5254.926574079209\n",
      "R-squared (R²): 0.8457770393492066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Khởi tạo evaluator cho các chỉ số\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Tính toán các chỉ số\n",
    "rmse = evaluator_rmse.evaluate(train_pred)\n",
    "mae = evaluator_mae.evaluate(train_pred)\n",
    "r2 = evaluator_r2.evaluate(train_pred)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"Fare\", maxBins=32, maxDepth=8,minInstancesPerNode=1, \\\n",
    "                           minInfoGain=0.01, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, featureSubsetStrategy='auto', \\\n",
    "                           seed=42, subsamplingRate=1.0)   \n",
    "pipeline3 = Pipeline(stages=indexers + encoders + [assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/25 13:25:27 WARN DAGScheduler: Broadcasting large task binary with size 1112.5 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_set, test_set = df_train.randomSplit([0.8, 0.2], seed=42)\n",
    "model_rf = pipeline3.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 864:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features|  Fare|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|(47,[1,9,19,23,26...| 75780| 53109.35826214447|\n",
      "|(47,[1,9,19,23,26...| 52215| 57822.68091134554|\n",
      "|(47,[1,9,19,23,26...| 35587|  51294.7894038727|\n",
      "|(47,[1,9,19,23,26...| 33828| 45591.26629063041|\n",
      "|(47,[1,9,19,23,26...| 41508| 54885.78492264815|\n",
      "|(47,[1,9,19,23,26...| 41508| 49518.62818442413|\n",
      "|(47,[1,9,19,23,26...| 53204| 46085.93492191007|\n",
      "|(47,[1,9,19,23,26...| 68052| 60901.20298859492|\n",
      "|(47,[1,9,19,21,26...| 68724|52198.744833209435|\n",
      "|(47,[1,9,19,21,26...| 59652|53114.067421182335|\n",
      "|(47,[1,9,19,21,26...| 61302| 52031.48399213698|\n",
      "|(47,[1,9,19,21,26...| 47220| 52031.48399213698|\n",
      "|(47,[1,9,19,21,26...| 41780| 47363.54378333789|\n",
      "|(47,[1,9,19,21,26...| 47332|60170.288903673376|\n",
      "|(47,[1,9,19,21,26...| 41508| 52229.38479709196|\n",
      "|(47,[1,9,19,21,26...| 29292| 49030.00113806026|\n",
      "|(47,[1,9,19,21,26...| 52215| 52771.15867159238|\n",
      "|(47,[1,9,19,21,26...|106203|54685.173625703654|\n",
      "|(47,[1,9,19,21,26...| 68881| 52286.96228686112|\n",
      "|(47,[1,9,19,21,26...| 41508|56347.410407662835|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_pred = model_rf.transform(test_set)\n",
    "train_pred.select(\"features\", \"Fare\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 875:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 7057.93126160127\n",
      "Mean Absolute Error (MAE): 4355.3236787189\n",
      "R-squared (R²): 0.8807869340356274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Khởi tạo evaluator cho các chỉ số\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Tính toán các chỉ số\n",
    "rmse = evaluator_rmse.evaluate(train_pred)\n",
    "mae = evaluator_mae.evaluate(train_pred)\n",
    "r2 = evaluator_r2.evaluate(train_pred)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²): {r2}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gb = GBTRegressor(featuresCol=\"features\", labelCol=\"Fare\", maxBins=32, maxIter=30 ,minInstancesPerNode=1, \\\n",
    "                  minInfoGain=0.01, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, stepSize=0.1, \\\n",
    "                  seed=42,subsamplingRate=1.0, impurity='variance', featureSubsetStrategy='all', validationTol=0.01)\n",
    "pipeline4 = Pipeline(stages=indexers + encoders  + [assembler, gb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_set, test_set = df_train.randomSplit([0.8, 0.2], seed=42)\n",
    "model_gb = pipeline4.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 847:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features|  Fare|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|(47,[1,9,19,23,26...| 75780|  50371.1836527247|\n",
      "|(47,[1,9,19,23,26...| 52215|56116.142918251484|\n",
      "|(47,[1,9,19,23,26...| 35587| 49994.66737092154|\n",
      "|(47,[1,9,19,23,26...| 33828|39576.865414777494|\n",
      "|(47,[1,9,19,23,26...| 41508|54779.322204949596|\n",
      "|(47,[1,9,19,23,26...| 41508| 43773.93282664018|\n",
      "|(47,[1,9,19,23,26...| 53204|45427.832032691746|\n",
      "|(47,[1,9,19,23,26...| 68052| 61054.60547727537|\n",
      "|(47,[1,9,19,21,26...| 68724| 52335.70592376635|\n",
      "|(47,[1,9,19,21,26...| 59652| 53836.20359778763|\n",
      "|(47,[1,9,19,21,26...| 61302|51409.300854806614|\n",
      "|(47,[1,9,19,21,26...| 47220| 52536.88970523532|\n",
      "|(47,[1,9,19,21,26...| 41780| 49407.88729843527|\n",
      "|(47,[1,9,19,21,26...| 47332| 63678.99858590961|\n",
      "|(47,[1,9,19,21,26...| 41508| 52739.71264689648|\n",
      "|(47,[1,9,19,21,26...| 29292|41925.318152850145|\n",
      "|(47,[1,9,19,21,26...| 52215|52245.158675389044|\n",
      "|(47,[1,9,19,21,26...|106203|59780.565700013634|\n",
      "|(47,[1,9,19,21,26...| 68881| 53033.05358152937|\n",
      "|(47,[1,9,19,21,26...| 41508| 55231.14521847629|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_pred = model_gb.transform(test_set)\n",
    "train_pred.select(\"features\", \"Fare\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 860:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 6720.927969301248\n",
      "Mean Absolute Error (MAE): 4145.848172692141\n",
      "R-squared (R²): 0.8918995528048023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Khởi tạo evaluator cho các chỉ số\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Tính toán các chỉ số\n",
    "rmse = evaluator_rmse.evaluate(train_pred)\n",
    "mae = evaluator_mae.evaluate(train_pred)\n",
    "r2 = evaluator_r2.evaluate(train_pred)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"Fare\", maxDepth=8, maxBins=32,minInstancesPerNode=1, minInfoGain=0.01, \\\n",
    "                           maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='variance', seed=42)\n",
    "pipeline5 = Pipeline(stages=indexers  + encoders +  [assembler, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_set, test_set = df_train.randomSplit([0.8, 0.2], seed=42)\n",
    "model_dt = pipeline5.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 832:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|            features|  Fare|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|(47,[1,9,19,23,26...| 75780| 44085.44668008048|\n",
      "|(47,[1,9,19,23,26...| 52215| 60415.95928080381|\n",
      "|(47,[1,9,19,23,26...| 35587| 51991.17093363479|\n",
      "|(47,[1,9,19,23,26...| 33828|  40659.5974130962|\n",
      "|(47,[1,9,19,23,26...| 41508|56228.718600228225|\n",
      "|(47,[1,9,19,23,26...| 41508| 51991.17093363479|\n",
      "|(47,[1,9,19,23,26...| 53204|  40659.5974130962|\n",
      "|(47,[1,9,19,23,26...| 68052| 60415.95928080381|\n",
      "|(47,[1,9,19,21,26...| 68724| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 59652| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 61302| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 47220| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 41780|  40659.5974130962|\n",
      "|(47,[1,9,19,21,26...| 47332| 62625.23382045929|\n",
      "|(47,[1,9,19,21,26...| 41508| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 29292| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 52215| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...|106203| 56809.25882352941|\n",
      "|(47,[1,9,19,21,26...| 68881| 51991.17093363479|\n",
      "|(47,[1,9,19,21,26...| 41508|56228.718600228225|\n",
      "+--------------------+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_pred = model_dt.transform(test_set)\n",
    "train_pred.select(\"features\", \"Fare\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 845:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 7141.9533848904985\n",
      "Mean Absolute Error (MAE): 4436.513036607309\n",
      "R-squared (R²): 0.8779316620958744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Khởi tạo evaluator cho các chỉ số\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Fare\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Tính toán các chỉ số\n",
    "rmse = evaluator_rmse.evaluate(train_pred)\n",
    "mae = evaluator_mae.evaluate(train_pred)\n",
    "r2 = evaluator_r2.evaluate(train_pred)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model_path = 'model2'\n",
    "model_gb.write().overwrite().save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
